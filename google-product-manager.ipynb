{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Google Product Manager Project <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "## Table of contents: \n",
    "* [Goal](#goal)\n",
    "* [Method](#method)\n",
    "* [Requirements](#requirements)\n",
    "* [Process](#process)\n",
    "    * [Authenticate](#auth)\n",
    "    * [List issues](#list)\n",
    "    * [Corpus](#corpus)\n",
    "    * [Cluster](#cluster)\n",
    "    * [Prioritize](#prioritize)\n",
    "\n",
    "## Goal <a class=\"anchor\" id=\"goal\"></a>\n",
    "\n",
    "The goal of this Jupyter notebook is to mine the information from Google's issue tracker to produce two prioritized list of features and bugs.\n",
    "\n",
    "[Go to top](#top)\n",
    "\n",
    "## Method <a class=\"anchor\" id=\"method\"></a>\n",
    "\n",
    "The following is a high-level strategy of attaining the above goal:\n",
    "\n",
    "1. Mine google's public issue tracker for raw data for features and bugs (the next steps are repeated for each)\n",
    "2. Extract the \"description\" of the issue.\n",
    "3. Use a vectorizer or natural language library to extract the text features (bigrams and unigrams)\n",
    "4. Use a unsupervised clustering algorithm to identify clusters of issues.\n",
    "5. Prioritize the top 3 clusters using an index generated by the number of issues and votes.\n",
    "6. Identify the scenario (W5H) for each cluster.\n",
    "7. Identify the persona for each cluster.\n",
    "8. Identify stories for each cluster.\n",
    "9. Priorize the stories.\n",
    "\n",
    "[Go to top](#top)\n",
    "\n",
    "## Requirements <a class=\"anchor\" id=\"requirements\"></a>\n",
    "\n",
    "1. Clone this repository.\n",
    "2. Ensure you have python3 and jupyter-notebook installed on your system.\n",
    "3. Create an virtual environment.\n",
    "4. Activate the virtual environment.\n",
    "5. Install the dependencies in the requirements.txt file.\n",
    "5. Run the command jupyter-notebook.\n",
    "6. Open the google-product-manager.ipynb document.\n",
    "\n",
    "[Go to top](#top)\n",
    "\n",
    "## Process <a class=\"anchor\" id=\"process\"></a>\n",
    "\n",
    "### Authenticate <a class=\"anchor\" id=\"auth\"></a>\n",
    "\n",
    "Google's issue tracker is public.  It allows anyone to report issues and request features.  The issue tracker does not have a supported API or SDK (that I can tell), but when loading the pages with developer mode enabled I can find a request that returns a JSON structure with the details necessary to do some kind of post-processing.\n",
    "\n",
    "When looking at the issue tracker in development mode, we can see that a XHR request is made using the following URL:\n",
    "\n",
    "* Bugs: https://issuetracker.google.com/action/issues?count=25&p=1&q=status:open+type:bug&s=created_time:desc\n",
    "* Features: https://issuetracker.google.com/action/issues?count=25&p=1&q=status:open+type:feature_request&s=created_time:desc\n",
    "\n",
    "Since the HTTP request requires authentication and there is no official API or SDK for the issue tracker, I used a browsercookie library in python to bypass the authentication piece (I tried using APIs, but had difficulty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firefox session filename does not exist: /home/daniel/.mozilla/firefox/edv7ja09.default/sessionstore.js\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import browsercookie\n",
    "import json\n",
    "\n",
    "cookies = browsercookie.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to top](#top)\n",
    "\n",
    "### Get list of issues <a class=\"anchor\" id=\"list\"></a>\n",
    "\n",
    "After looking at the response, I found several caveats:\n",
    "* The response is multi-line and the first line is not valid json.\n",
    "* The syntax required the character \"+\" which the python requests library encodes by default.\n",
    "\n",
    "I created two queries that would produce a list of bugs and issues sorted by their creation date.  I then wrote some code that would pull down a list of issues for each query and work around some of these limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fd6b659cd41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mbugs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_issues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bug'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_issues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feauter_request'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Found {} bugs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbugs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-fd6b659cd41d>\u001b[0m in \u001b[0;36mpull_issues\u001b[0;34m(issue_type, issue_limit)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://issuetracker.google.com/action/issues?count=1000&p=1&q=status:open+type:&s=created_time:desc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0missue_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_request\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+type:&\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+type:{}&\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missue_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def pull_issues(issue_type, issue_limit=5000):\n",
    "    url = \"https://issuetracker.google.com/action/issues?count=1000&p=1&q=status:open+type:&s=created_time:desc\"\n",
    "    \n",
    "    assert issue_type in [\"feature_request\", \"bug\"]\n",
    "    url.replace(\"+type:&\", \"+type:{}&\".format(issue_type))\n",
    "    page = 1\n",
    "    issues = []\n",
    "    \n",
    "    while(True):\n",
    "        response = requests.get(bug_url, cookies=cookies)\n",
    "        lines = [x for x in response.iter_lines()] # workaround for first line.\n",
    "        issues = json.loads(lines[1].decode())['issues']\n",
    "    \n",
    "        if len(issues) == 0:\n",
    "            break\n",
    "        elif len(bugs) >= issue_limit:\n",
    "            break\n",
    "        else:\n",
    "            issues.extend(issues)\n",
    "            url.replace(\"&p=\" + str(page), \"&p=\" + str(page + 1))\n",
    "            page += 1\n",
    "    \n",
    "    \n",
    "    return issues\n",
    "    \n",
    "bugs = pull_issues('bug')\n",
    "features = pull_issues('feauter_request')\n",
    "\n",
    "print(\"Found {} bugs\".format(len(bugs)))\n",
    "print(\"Found {} features\".format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Go to top](#top)\n",
    "\n",
    "### Corpus <a class=\"anchor\" id=\"corpus\"></a>\n",
    "\n",
    "If we inspect a single issue, we can take a look at the some the data within, but the only text data that we see is the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom sizing for each individual page\n"
     ]
    }
   ],
   "source": [
    "print(features[0]['snapshot'][0]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we are able to open each issue using a similar request that makes use of the issue ID.  An example for the issue above is \n",
    "\n",
    "https://issuetracker.google.com/action/issues/74163608\n",
    "\n",
    "The structure looks like the zero-indexed comment or the initial comment is similar to a verbose description of the problem or feature request.  Let's try making a HTTP request using the same trick as above to get a description for each issue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it possible to get the feature added to get individual sizing for each page on a datastudio report.<br>We have one page on a report that requires 900+ length and another that requires 600 to avoid scrolling an empty canvas.<br><br>This will be especially useful when it comes to embedding pages on a site or elsewhere for readability.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://issuetracker.google.com/action/issues/74163608\", cookies=cookies)\n",
    "lines = [x for x in response.iter_lines()]\n",
    "the_issue = json.loads(lines[1].decode())\n",
    "\n",
    "print(the_issue['events'][0]['comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some text, we can try to cluster the text to see what groups come out of it.  Will be using this guide as inspiration: https://pythonprogramminglanguage.com/kmeans-text-clustering/\n",
    "\n",
    "Let's start by creating a corpus to cluster and cleaning up the text so that it does not contain HTML or escaped characters.  \n",
    "\n",
    "**WARNING:** This operation is very time consuming, so I have written it in a way that the results are stored in local text files.  If you want to limit the number of issues you are clustering, please add a range in the \"for feature in features:\" line; for example, \"for feature in features[:5]:\" will only download the details for 5 issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved 4990 documents.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    # Attempt to open a pre-existing file with feature descriptions.\n",
    "    with open('feature_documents.pickle', 'rb') as f:\n",
    "        feature_documents = pickle.load(f)\n",
    "        \n",
    "    print(\"Found {} saved documents.\".format(len(feature_documents)))\n",
    "\n",
    "except FileNotFoundError:\n",
    "\n",
    "    # If a file does not exist, then pull it manually.\n",
    "    feature_documents = []\n",
    "    \n",
    "    for feature in features:\n",
    "        url = \"https://issuetracker.google.com/action/issues/\" + str(feature['issueId'])\n",
    "        response = requests.get(url, cookies=cookies)\n",
    "        lines = [x for x in response.iter_lines()]\n",
    "        try:\n",
    "            first_comment = json.loads(lines[1].decode())['events'][0]['comment']\n",
    "            document = re.sub('<[^<]+?>', '', first_comment) # There appears to be HTML formatting support in comments.\n",
    "            document = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', document, flags=re.MULTILINE) # Remove URLs.\n",
    "            document = html.unescape(document)\n",
    "            feature_documents.append(document)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    with open('feature_documents.pickle', 'wb') as f:\n",
    "        pickle.dump(feature_documents, f)\n",
    "        \n",
    "    print(\"Downloaded and saved {} documents.\".format(len(feature_documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to top](#top)\n",
    "### Cluster  <a class=\"anchor\" id=\"cluster\"></a>\n",
    "\n",
    "Now, lets apply some of the machine learning k-means clustering goodness to produce some a list of top 10 features in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per feature cluster:\n",
      "\n",
      "Feature cluster 0:\n",
      " kml\n",
      " refresh interval\n",
      " support kml\n",
      " kml markup\n",
      " kml links\n",
      " kml file\n",
      " interval set\n",
      " generating\n",
      " generating dynamic\n",
      " dynamic\n",
      "\n",
      "Feature cluster 1:\n",
      " migrate slack\n",
      " chatwhat\n",
      " google chatwhat\n",
      " migrate\n",
      " slack\n",
      " content\n",
      " provide\n",
      " existing\n",
      " google\n",
      " search\n",
      "\n",
      "Feature cluster 2:\n",
      " ad\n",
      " ad server\n",
      " impressions\n",
      " server\n",
      " track\n",
      " revenue\n",
      " impression\n",
      " impression client\n",
      " impressions clicks\n",
      " impressions viewed\n",
      "\n",
      "Feature cluster 3:\n",
      " spaces\n",
      " script api\n",
      " script\n",
      " api\n",
      " reference\n",
      " google\n",
      " reference rest\n",
      " members\n",
      " rest\n",
      " developers google\n",
      "\n",
      "Feature cluster 4:\n",
      " api\n",
      " add\n",
      " id\n",
      " like add\n",
      " add api\n",
      " warning\n",
      " api project\n",
      " include api\n",
      " project id\n",
      " warning include\n",
      "\n",
      "Feature cluster 5:\n",
      " provide\n",
      " existing\n",
      " search\n",
      " requested\n",
      " request\n",
      " api tools\n",
      " tools requested\n",
      " current api\n",
      " present current\n",
      " receive\n",
      "\n",
      "Feature cluster 6:\n",
      " shape\n",
      " send\n",
      " page\n",
      " specific\n",
      " line\n",
      " current\n",
      " screen send\n",
      " instantly\n",
      " instantly current\n",
      " situations developer\n",
      "\n",
      "Feature cluster 7:\n",
      " dashboard\n",
      " copy\n",
      " android studio\n",
      " copy dashboard\n",
      " studio\n",
      " dataflow\n",
      " dashboard missing\n",
      " data read\n",
      " work fine\n",
      " selected dashboard\n",
      "\n",
      "Feature cluster 8:\n",
      " report\n",
      " create\n",
      " relation\n",
      " report create\n",
      " data source\n",
      " relation databases\n",
      " source report\n",
      " databases\n",
      " create relation\n",
      " necessary data\n",
      "\n",
      "Feature cluster 9:\n",
      " android\n",
      " important read\n",
      " required information\n",
      " bugs\n",
      " required\n",
      " android com\n",
      " layout\n",
      " important\n",
      " ai\n",
      " ai 171\n",
      "\n",
      "Feature cluster 10:\n",
      " dfp\n",
      " dimensions\n",
      " time\n",
      " using improved\n",
      " monitoringcampaign\n",
      " monitoringcampaign tracking\n",
      " enhancements\n",
      " enhancements dfp\n",
      " connectorallow\n",
      " users time\n",
      "\n",
      "Feature cluster 11:\n",
      " code appear\n",
      " problem rows\n",
      " location attributes\n",
      " city state\n",
      " state\n",
      " attributes\n",
      " attributes city\n",
      " rows location\n",
      " hi problem\n",
      " state zip\n",
      "\n",
      "Feature cluster 12:\n",
      " column\n",
      " update\n",
      " map\n",
      " style\n",
      " table\n",
      " update entire\n",
      " replacing\n",
      " worth data\n",
      " widgets\n",
      " single column\n",
      "\n",
      "Feature cluster 13:\n",
      " table\n",
      " rows\n",
      " cli\n",
      " filter\n",
      " connect\n",
      " client\n",
      " want\n",
      " results\n",
      " 41\n",
      " selecting filter\n",
      "\n",
      "Feature cluster 14:\n",
      " dependency\n",
      " corresponding\n",
      " transitive dependency\n",
      " dependency corresponding\n",
      " currently module\n",
      " module direct\n",
      " require transitive\n",
      " transitive\n",
      " nice require\n",
      " base nice\n",
      "\n",
      "Feature cluster 15:\n",
      " avro\n",
      " bigtable\n",
      " external\n",
      " bigquery\n",
      " data\n",
      " bigquery external\n",
      " documented\n",
      " needs exported\n",
      " sources support\n",
      " value_encoding\n",
      "\n",
      "Feature cluster 16:\n",
      " disks\n",
      " committed\n",
      " useful users\n",
      " discounts\n",
      " committed use\n",
      " use discounts\n",
      " useful\n",
      " gcp\n",
      " users\n",
      " snapshot\n",
      "\n",
      "Feature cluster 17:\n",
      " role\n",
      " compute\n",
      " custom\n",
      " use compute\n",
      " custom role\n",
      " compute healthchecks\n",
      " healthchecks\n",
      " roles\n",
      " permissions\n",
      " iam\n",
      "\n",
      "Feature cluster 18:\n",
      " hidden\n",
      " breakstrategy constructor\n",
      " need pass\n",
      " constructor parameter\n",
      " pass breakstrategy\n",
      " pass\n",
      " mistake\n",
      " breakstrategy\n",
      " hidden mistake\n",
      " hidden hidden\n",
      "\n",
      "Feature cluster 19:\n",
      " connections\n",
      " cloud function\n",
      " quota\n",
      " function\n",
      " cloud\n",
      " limits\n",
      " quotas\n",
      " increased\n",
      " bursty webhook\n",
      " experienced\n",
      "\n",
      "Feature cluster 20:\n",
      " madlib\n",
      " apache\n",
      " analytics\n",
      " database analytics\n",
      " apache madlib\n",
      " database\n",
      " math operations\n",
      " source library\n",
      " useful database\n",
      " statistical machine\n",
      "\n",
      "Feature cluster 21:\n",
      " using\n",
      " impact\n",
      " plan\n",
      " impact business\n",
      " plan using\n",
      " business time\n",
      " business\n",
      " time\n",
      " remember vote\n",
      " vote\n",
      "\n",
      "Feature cluster 22:\n",
      " e3\n",
      " 81\n",
      " e3 81\n",
      " e3 82\n",
      " 82\n",
      " 8c\n",
      " e5\n",
      " e8\n",
      " 8b\n",
      " 88\n",
      "\n",
      "Feature cluster 23:\n",
      " sql\n",
      " cloud\n",
      " com sql\n",
      " cloud google\n",
      " https cloud\n",
      " com\n",
      " https\n",
      " mysql\n",
      " docs mysql\n",
      " sql docs\n",
      "\n",
      "Feature cluster 24:\n",
      " hd\n",
      " android support\n",
      " thanks\n",
      " screen\n",
      " support\n",
      " android\n",
      " screen hd\n",
      " ok ubuntu\n",
      " hd ok\n",
      " hd thanks\n",
      "\n",
      "Feature cluster 25:\n",
      " provided\n",
      " console\n",
      " charges month\n",
      " charges\n",
      " billing\n",
      " cloud console\n",
      " cloud\n",
      " dashboard\n",
      " view\n",
      " month\n",
      "\n",
      "Feature cluster 26:\n",
      " pop\n",
      " app engine\n",
      " headers\n",
      " engine\n",
      " run\n",
      " particular\n",
      " work\n",
      " useful\n",
      " app\n",
      " able\n",
      "\n",
      "Feature cluster 27:\n",
      " ter gauges\n",
      " ter\n",
      " gauges\n",
      " precisa ter\n",
      " precisa\n",
      " 表の行列入れ替えhttps support\n",
      " environment\n",
      " entirely\n",
      " entirely google\n",
      " entities\n",
      "\n",
      "Feature cluster 28:\n",
      " course\n",
      " list\n",
      " courses\n",
      " courses list\n",
      " metadata\n",
      " students\n",
      " students course\n",
      " student\n",
      " property course\n",
      " number students\n",
      "\n",
      "Feature cluster 29:\n",
      " español\n",
      " que\n",
      " en\n",
      " en español\n",
      " poder utilizarlo\n",
      " garantías\n",
      " produjeran algún\n",
      " hola\n",
      " hola sería\n",
      " para\n",
      "\n",
      "Feature cluster 30:\n",
      " log\n",
      " stackdriver\n",
      " stackdriver log\n",
      " gzip\n",
      " user\n",
      " compression\n",
      " daily weekly\n",
      " daily\n",
      " log export\n",
      " log entries\n",
      "\n",
      "Feature cluster 31:\n",
      " recording\n",
      " record\n",
      " background\n",
      " user\n",
      " contract\n",
      " app\n",
      " countries\n",
      " telemarketer\n",
      " mic\n",
      " recording filmning\n",
      "\n",
      "Feature cluster 32:\n",
      " link\n",
      " just\n",
      " check\n",
      " launcher\n",
      " app engine\n",
      " documentation\n",
      " download\n",
      " engine\n",
      " update\n",
      " window\n",
      "\n",
      "Feature cluster 33:\n",
      " apps script\n",
      " apps\n",
      " script\n",
      " provide\n",
      " existing\n",
      " search\n",
      " request\n",
      " requested\n",
      " use\n",
      " believe\n",
      "\n",
      "Feature cluster 34:\n",
      " datastore\n",
      " emulator\n",
      " test\n",
      " production\n",
      " gcloud\n",
      " help making\n",
      " bigtable datastore\n",
      " services bigtable\n",
      " production platform\n",
      " bringing\n",
      "\n",
      "Feature cluster 35:\n",
      " instances\n",
      " cpu instances\n",
      " cpu\n",
      " pool\n",
      " great\n",
      " build times\n",
      " higher cpu\n",
      " n1\n",
      " n1 standard\n",
      " higher\n",
      "\n",
      "Feature cluster 36:\n",
      " script\n",
      " started\n",
      " know\n",
      " problem wrote\n",
      " logged\n",
      " reads\n",
      " reads cells\n",
      " feel\n",
      " feel like\n",
      " script usage\n",
      "\n",
      "Feature cluster 37:\n",
      " signal\n",
      " network\n",
      " house\n",
      " wifi\n",
      " wifi networks\n",
      " currently connected\n",
      " signal strength\n",
      " networks\n",
      " strength\n",
      " drops\n",
      "\n",
      "Feature cluster 38:\n",
      " allow overriding\n",
      " chance\n",
      " 67885054 simple\n",
      " 67885054\n",
      " eventually thanks\n",
      " gory details\n",
      " overriding individual\n",
      " gory\n",
      " eventually\n",
      " fields\n",
      "\n",
      "Feature cluster 39:\n",
      " calendar\n",
      " locale\n",
      " previous\n",
      " locale getdefault\n",
      " getdefault\n",
      " purposes\n",
      " new calendar\n",
      " style\n",
      " problematic\n",
      " dd\n",
      "\n",
      "Feature cluster 40:\n",
      " serviceaccountsperproject\n",
      " serviceaccountsperproject quota\n",
      " quota limit\n",
      " limit\n",
      " quota\n",
      " adjusted\n",
      " limit adjusted\n",
      " api\n",
      " possible\n",
      " api script\n",
      "\n",
      "Feature cluster 41:\n",
      " partition\n",
      " _partitiontime\n",
      " table\n",
      " latest partition\n",
      " latest\n",
      " project dataset\n",
      " scanning\n",
      " entire table\n",
      " workaround\n",
      " table use\n",
      "\n",
      "Feature cluster 42:\n",
      " device\n",
      " screen\n",
      " turn screen\n",
      " turn\n",
      " lock\n",
      " iot\n",
      " android\n",
      " speed\n",
      " devicepolicymanager\n",
      " way turn\n",
      "\n",
      "Feature cluster 43:\n",
      " drive\n",
      " drive api\n",
      " allows\n",
      " api does\n",
      " id\n",
      " permissions\n",
      " api\n",
      " calendar\n",
      " function allows\n",
      " app script\n",
      "\n",
      "Feature cluster 44:\n",
      " tasks\n",
      " google tasks\n",
      " google\n",
      " place\n",
      " view\n",
      " view edit\n",
      " edit google\n",
      " mobile\n",
      " edit\n",
      " calendar\n",
      "\n",
      "Feature cluster 45:\n",
      " dashboards\n",
      " analytics\n",
      " google analytics\n",
      " user\n",
      " analytics like\n",
      " increase ease\n",
      " analytics data\n",
      " property increase\n",
      " removed google\n",
      " access dashboards\n",
      "\n",
      "Feature cluster 46:\n",
      " handler\n",
      " catch handler\n",
      " catch\n",
      " instantiated\n",
      " known\n",
      " switch\n",
      " accounts\n",
      " instantiated referenced\n",
      " instantiated class\n",
      " r8\n",
      "\n",
      "Feature cluster 47:\n",
      " cost twillo\n",
      " service low\n",
      " low cost\n",
      " costly\n",
      " costly used\n",
      " integration\n",
      " integration service\n",
      " india\n",
      " twillo\n",
      " twillo costly\n",
      "\n",
      "Feature cluster 48:\n",
      " image spreadsheet\n",
      " spreadsheet dimension\n",
      " insert\n",
      " insert image\n",
      " image\n",
      " spreadsheet\n",
      " dimension\n",
      " engine provides\n",
      " environment production\n",
      " entities\n",
      "\n",
      "Feature cluster 49:\n",
      " heroku postgres\n",
      " heroku\n",
      " connection\n",
      " postgres\n",
      " doesn\n",
      " database unfortunately\n",
      " problem heroku\n",
      " studio plans\n",
      " plans\n",
      " plans support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"feature\", \"features\", \"issue\", \"issues\", \"requests\", \"requests\", \"thing\", \"things\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2))\n",
    "x = vectorizer.fit_transform(documents)\n",
    "\n",
    "number_of_clusters = 50\n",
    "feature_model = KMeans(n_clusters=number_of_clusters, init='k-means++', max_iter=100, n_init=1)\n",
    "feature_model.fit(x)\n",
    "\n",
    "print(\"Top terms per feature cluster:\")\n",
    "print()\n",
    "order_centroids = feature_model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    print(\"Feature cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can make predictions of which cluster a string belongs to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following command belongs in cluster 21:\n",
      "We're requesting a feature to log the Network LB (internal and external) traffic in Stackdriver Logging. 1. Access Timestamp2. Source IP3. Destination IP4. An indication of connection success/failure\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0, len(features))\n",
    "\n",
    "url = \"https://issuetracker.google.com/action/issues/\" + str(feature['issueId'])\n",
    "response = requests.get(url, cookies=cookies)\n",
    "lines = [x for x in response.iter_lines()]\n",
    "first_comment = json.loads(lines[1].decode())['events'][0]['comment']\n",
    "document = re.sub('<[^<]+?>', '', first_comment) # There appears to be HTML formatting support in comments.\n",
    "document = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', document, flags=re.MULTILINE) # Remove URLs.\n",
    "document = html.unescape(document)\n",
    "\n",
    "y = vectorizer.transform([document])\n",
    "prediction = feature_model.predict(y)\n",
    "\n",
    "print(\"The following command belongs in cluster {}:\".format(prediction[0]))\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Go to top](#top)\n",
    "\n",
    "### Prioritize  <a class=\"anchor\" id=\"prioritize\"></a>\n",
    "\n",
    "I have created a model that has used a sample of 100 features to \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpm",
   "language": "python",
   "name": "gpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
